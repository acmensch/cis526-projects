#!/usr/bin/env python
# -*- coding: utf-8 -*-
import optparse
from collections import defaultdict
import glob # for file opening
import json
import operator
import re
import sys
reload(sys)
sys.setdefaultencoding('utf-8')


'''
Baseline system
Baseline: Your output is printed out, one language per line.
This works by getting the most common trigrams from the training data, and testing each word for the
presence of each trigram (and adding points based on that). The more matching trigrams, the more likely
the language.
This also creates an alphabet using the training data for each language, and adds points to the 
language if the test phrase also has components of the alphabet.
It is somewhat similar to Grefenstette: Comparing Two Language Identification Systems, but we don't
hardcode in the trigrams.
How to run: baseline | grade
'''

optparser = optparse.OptionParser()
optparser.add_option("-t", "--test", dest="test", default="test.small", help="Test set (default=test.small)")
(opts, _) = optparser.parse_args()

languages = defaultdict(float)
# Makes a dictionary of all the words for each wiki article
# Format [{english : ['a', 'the', 'cake']}]
multidict = defaultdict(list)
multichar = defaultdict(set)
trigram = defaultdict(lambda: defaultdict(list)) # trigram frequencies for each lang
#trigram = defaultdict(dict)
charset = [] # list used for getting unique chars
for filename in glob.glob('data/*.*'):
  with open(filename) as f:
    lang = filename[10:]
    languages[lang] = 0
    charset = []
    chars = set(charset) # makes a new set from list of unique chars
    for line in f:
      words = line.split()
      for word in words:
        if word not in multidict[lang]:
          multidict[lang].append(word)
          for i in range(0, len(word)):
            chars.update(word[i]) #adds char to set
      multichar[lang].update(chars)
      #trigram maker
      for i in range (0, len(line)-3):
        if line[i:i+3] in trigram[lang]:
          trigram[lang][line[i:i+3]] += 1
        else: 
          trigram[lang][line[i:i+3]] = 1
    sys.stderr.write("Put the words in the file " + filename + " in dict\n")
sys.stderr.write("Completed data dictionary making\n");

for lang in trigram:
  trigram[lang] = sorted(trigram[lang].iteritems(), key=operator.itemgetter(1), reverse=True)
  trigram[lang] = trigram[lang][:100]
#  print (str(trigram[lang]))

# Makes a dictionary using trigrams with wildcards
# trigramdict = defaultdict(list)
# trigramdict['danish'] = ['er.', 'en.', 'for', 'et.', 'ing', '.fo', '.af', '.de', 'nde', 'els', 'lse', 'ret', '.sa', 'der', '.i.']
# trigramdict['dutch'] = ['en.', 'de.', '.de', 'et.', 'an.', 'n.d', '.he', 'er.', '.va', 'van', 'een', 'ver', 'aar', '.ee', 'het']
# trigramdict['english'] = ['.th', 'he.', 'the', '.,.', 'nd.', 'ed.', '.an', 'and', '.\..', '.to', 'ing', 'to.', 'ng.', 'er.', '.of']
# trigramdict['french'] = ['.de', 'es.', 'de.', 'ent', 'nt.', '.le', 'e.d', 'le.', 'ion', 's.d', 'e.l', '.la', 're.', 'on.']
# trigramdict['german'] = ['en.', 'er.', '.de', 'der', 'ie.', 'ich', 'sch', 'ein', 'che', 'die', 'ch.', 'den', 'nd.', '.di', 'ung']
# trigramdict['italian'] = ['.di', 'to.', '.de', 'di.', '.co', 'la.', 're.', 'ion', 'ent', 'e.d', 'le.', 'o.d', 'ne.', 'no.', '.in']
# trigramdict['spanish'] = ['.de','de.','os.','.la','el.','la.','que','as.','ue.','.qu','.co','.en','en.','ent','es.']
# trigramdict['portuguese']= ['.de','de.','os.','do.','que','.qu','.co','as.','ent','o.','ue.','.a.','o.d','.se','.o.']
# trigramdict['swedish'] = ['en.', '.\..', 'er.', 'et.', 'tt.', '.de', 'ar.', '.,.', 'fr', 'om.', '.oc', 'ch.', 'de.', 'och', 'an.']
# trigramdict['romanian'] = ['.a', '.u', u'\203', u'\226' u'\xa2', u'\xc8', u'\x9b']
# trigramdict['czech'] = [u'Ã', u'Å¾']
# sys.stderr.write("Completed trigram dictionary making\n");

# Counts whether each word appears in each dictionary
for i, line in enumerate(open("data/test/" + opts.test)):
  words = []
  if len(line)>1: # ignore newlines
    words = line.split()
    for word in words:

      # Checks if each word is in the wiki or text article or not
      for lang in multidict:
        if word in multidict[lang]:
          languages[lang] += 1.0

       # checks against trigrams
      for lang in trigram:
        for (tri, freq) in trigram[lang]:
          if tri in word:
            languages[lang] += 0.5

       # checks for presence of alphabet characters
      for lang in multichar:
        for char in multichar[lang]:
          if char in word:
            languages[lang] += 0.00001

    first = str(max(languages.iteritems(), key=operator.itemgetter(1))[0])
    second = str(max(languages.iteritems(), key=operator.itemgetter(1))[1])
    if (languages[first] == languages[second]):
      print "uncertain"
    # ignore this
    #   words = []
    #   for lang in languages:
    #     languages[lang] = 0.0
    #   if len(line)>1: # ignore newlines
    #     words = line.split()
    #     for word in words:
    #       # checks against trigrams
    #       for lang in trigramdict:
    #         for trigram in trigramdict[lang]:
    #           regex = re.compile(trigram, re.UNICODE)
    #           if re.match(regex, word):
    #             languages[lang] += 1.0
    #   first = str(max(languages.iteritems(), key=operator.itemgetter(1))[0])
    #   second = str(max(languages.iteritems(), key=operator.itemgetter(1))[1])
    #   if (languages[first] == languages[second]):
    #     print 'uncertain'
    #   else:
    #     print first
    else:
      print first
  else:
    print ""
  # Resets language dict for next sentence
  for lang in languages:
    languages[lang] = 0.0
